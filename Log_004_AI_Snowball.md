# [Log #004] 관찰자의 노트: AI 오류의 스노우볼 효과

### 1. 작은 실수가 눈덩이처럼: 스노우볼 효과
AI 시스템에서 발생하는 실수는 단순한 더하기가 아니라, **'복리이자'**처럼 불어나는 성질이 있다. 전문 용어로는 '오류 전파(Error Propagation)'라고 하지만, 우리는 이를 **'AI 스노우볼 효과'**라고 부를 수 있다.

마치 산꼭대기에서 굴러내린 작은 눈뭉치가 산 아래에서는 거대한 눈사태가 되듯이, AI의 초기 단계에서 발생한 1%의 미세한 오해가 다음 단계로 넘어가며 100%의 사고로 커지는 것이다. 최근 학계에서 경고하는 '모델 붕괴' 현상도 이와 비슷하다. AI가 만든 부정확한 정보를 다른 AI가 앵무새처럼 따라 배우다 보면, 결국 진실은 사라지고 엉뚱한 정보만 남게 된다.

### 2. SI 개발자의 미래: "벽돌공에서 감리사로"
이러한 AI의 위험한 특성 때문에, 시스템 통합(SI) 현장의 풍경도 바뀌고 있다. AI가 코딩 속도(생산성)를 높여주는 건 맞지만, 동시에 **'잘못된 눈덩이'**를 굴릴 위험도 커졌기 때문이다.

그래서 미래의 개발자는 직접 벽돌을 쌓는 사람(Coder)보다는, AI가 쌓은 벽이 튼튼한지 검사하는 **'현장 감리사(Auditor)'**가 되어야 한다.
* **불량 검출:** AI가 짠 코드에 숨어있는 '거짓말(할루시네이션)'이나 '보안 구멍'을 찾아내는 일.
* **현장 맞춤:** 교과서적인 AI 코드를 우리 회사의 복잡한 현실(세법, 사규 등)에 딱 맞게 조립하는 일.

### 3. 결국 책임은 인간의 몫
기업이 비싼 돈을 들여 전문 업체를 쓰는 이유는 기술 때문만이 아니다. **"문제가 생기면 누가 책임질 것인가?"**라는 질문에 답을 얻기 위해서다. AI는 사고를 쳐도 책임지지 않는다.

결국 시스템이 멈췄을 때 책임을 지고 해결할 수 있는 건 사람뿐이다. 도구가 똑똑해질수록, 전체를 설계하고 위험을 통제하는 **'설계자(Architect)'**의 가치는 오히려 더 빛날 것이다. 기술은 쉬워졌지만, 신뢰를 지키는 일은 더 중요해졌기 때문이다.
